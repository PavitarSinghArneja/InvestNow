# -*- coding: utf-8 -*-
"""Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yJJo6bRi0jb4ji20Dn7SXcx6OnVzSTzY
"""

import pandas as pd

# Load the Excel file
try:
    df = pd.read_excel("nifty_50.xlsx", engine="openpyxl")
except FileNotFoundError:
    print("Error: 'nifty_50.xlsx' not found.")
except Exception as e:
    print(f"An error occurred: {e}")
else:
    # Rename the first column to 'Date' if it's unnamed or incorrect
    df.rename(columns={df.columns[0]: "Date"}, inplace=True)

    # Convert the 'Date' column to datetime format
    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')

    # Drop rows where 'Date' conversion failed
    df.dropna(subset=['Date'], inplace=True)

    # Set 'Date' as the index
    df.set_index('Date', inplace=True)

    # Display basic info
    print("Data loaded successfully.")
    print("Shape of DataFrame:", df.shape)
    print("Index:", df.index.name)
    print("Columns:", df.columns.tolist())
    display(df.head())

!pip install pandas numpy statsmodels matplotlib

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import adfuller

'''def apply_arima(df, forecast_days=30):
    results = {}  # Store results for each company

    for company in df.columns:
        print(f"\n🔹 Processing: {company}...")

        # Extract company time series
        series = df[company].copy()

        # Step 1: Fill missing values using forward fill
        series = series.ffill()

        # Step 2: Check stationarity
        adf_result = adfuller(series.dropna())
        p_value = adf_result[1]

        # Step 3: Apply differencing if needed
        d = 0 if p_value < 0.05 else 1  # Differencing only if necessary

        # Step 4: Fit ARIMA model
        try:
            model = ARIMA(series, order=(1, d, 1))
            model_fit = model.fit()

            # Step 5: Forecast
            forecast = model_fit.forecast(steps=forecast_days)
            results[company] = forecast

            # Print Forecasted Values
            print(f"\n📊 Forecasted Prices for {company}:")
            print(forecast)  # Print actual forecast numbers

            # Plot actual vs forecast
            plt.figure(figsize=(10, 4))
            plt.plot(series, label="Actual Prices", color="blue")
            plt.plot(pd.date_range(series.index[-1], periods=forecast_days+1, freq='B')[1:],
                     forecast, label="Forecasted Prices", linestyle="dashed", color="red")
            plt.legend()
            plt.title(f"ARIMA Forecast for {company}")
            plt.show()

        except Exception as e:
            print(f"❌ Error processing {company}: {e}")

    return results

# Run the function
forecasts = apply_arima(df, forecast_days=30)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import adfuller
from sklearn.metrics import mean_absolute_percentage_error

def apply_arima_with_accuracy(df, test_start="2025-02-05", test_end="2025-03-06"):
    """
    Applies ARIMA forecasting for each company in the dataset,
    evaluates accuracy by comparing forecasts with actual values,
    and plots the results.

    Parameters:
    df (pd.DataFrame): Stock price data with Date as index and companies as columns.
    test_start (str): Start date of the test set.
    test_end (str): End date of the test set.

    Returns:
    results (dict): Forecasted values for each company.
    accuracy_scores (dict): Accuracy percentage for each company.
    """

    results = {}  # Stores forecasted prices
    accuracy_scores = {}  # Stores accuracy percentages

    # 🔹 Loop through each company in the dataset
    for company in df.columns:
        print(f"\n🔹 Processing: {company}...")

        # ✅ STEP 1: Prepare Data (Fill Missing Values)
        series = df[company].copy()
        series = series.ffill()  # Forward-fill missing values

        # ✅ STEP 2: Split Data into Training & Testing Sets
        train_data = series.loc[:test_start]  # Data before test period
        test_data = series.loc[test_start:test_end]  # Future actual values

        # ✅ STEP 3: Check for Stationarity (Augmented Dickey-Fuller Test)
        adf_result = adfuller(train_data.dropna())
        p_value = adf_result[1]
        d = 0 if p_value < 0.05 else 1  # Differencing only if necessary

        # ✅ STEP 4: Train ARIMA Model
        try:
            model = ARIMA(train_data, order=(1, d, 1))  # ARIMA(p=1, d, q=1)
            model_fit = model.fit()

            # ✅ STEP 5: Make Predictions for Test Period
            forecast = model_fit.forecast(steps=len(test_data))
            results[company] = forecast
            forecast.index = test_data.index
            results[company] = forecast
            # ✅ STEP 6: Evaluate Accuracy (MAPE & Average Prediction Gap)
            mape = mean_absolute_percentage_error(test_data, forecast) * 100  # Convert to percentage
            accuracy = 100 - mape  # Accuracy in %

            accuracy_scores[company] = accuracy  # Store accuracy

            # ✅ STEP 7: Display Results
            print(f"\n📊 Forecasted vs Actual Prices for {company}:")
            comparison = pd.DataFrame({"Actual": test_data, "Predicted": forecast})
            print(comparison)

            print(f"\n✅ Accuracy for {company}: {accuracy:.2f}%")
            print(f"🔻 Average Prediction Gap: {np.mean(np.abs(test_data - forecast)):.2f}")

            # ✅ STEP 8: Plot Actual vs Forecasted Prices
            plt.figure(figsize=(10, 4))
            plt.plot(series, label="Actual Prices", color="blue")
            plt.plot(pd.date_range(test_start, periods=len(forecast), freq='B'),
                     forecast, label="Forecasted Prices", linestyle="dashed", color="red")
            plt.legend()
            plt.title(f"ARIMA Forecast & Accuracy for {company}")
            plt.show()

        except Exception as e:
            print(f"❌ Error processing {company}: {e}")

    return results, accuracy_scores

# 🔹 RUN THE FUNCTION & GET RESULTS
forecasts, accuracies = apply_arima_with_accuracy(df)

# ✅ STEP 9: Print Overall Accuracy Report
print("\n📊 Overall Model Accuracy Report:")
for company, acc in accuracies.items():
    print(f"{company}: {acc:.2f}%")

import pandas as pd
import numpy as np

# ---------------------------
# Step 1: Load Historical Price Data
# ---------------------------
df = pd.read_excel("nifty_50.xlsx", engine="openpyxl")
df.rename(columns={df.columns[0]: "Date"}, inplace=True)
df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
df.dropna(subset=['Date'], inplace=True)
df.set_index('Date', inplace=True)

# ---------------------------
# Step 2: Calculate Daily Returns & Risk (Std Dev)
# ---------------------------
daily_returns = df.pct_change().dropna()
risk = daily_returns.std()  # Risk = volatility

# ---------------------------
# Step 3: ARIMA Predictions (Mock or Loaded)
# ---------------------------
# Simulated predictions (replace with your real ARIMA model output)
predicted_returns = {
    col: np.random.uniform(0.05, 0.20) for col in df.columns  # Simulated 5%–20% annual return
}
predictions_df = pd.DataFrame.from_dict(predicted_returns, orient='index', columns=['Predicted_Return'])
predictions_df['Risk'] = risk

# ---------------------------
# Step 4: Scoring Stocks using Sharpe Ratio
# ---------------------------
predictions_df['Sharpe'] = predictions_df['Predicted_Return'] / predictions_df['Risk']
predictions_df.dropna(inplace=True)

# ---------------------------
# Step 5: User Input
# ---------------------------
investment_amount = float(input("💰 Enter the amount to invest (e.g., 100000): "))
risk_tolerance = input("📊 Enter your risk tolerance (high, intermediate, low): ").strip().lower()

# ---------------------------
# Step 6: Adjust Scores Based on Risk Tolerance
# ---------------------------
# Normalize Scores
predictions_df['Return_Score'] = (predictions_df['Predicted_Return'] - predictions_df['Predicted_Return'].min()) / \
                                 (predictions_df['Predicted_Return'].max() - predictions_df['Predicted_Return'].min())

predictions_df['Risk_Score'] = (predictions_df['Risk'].max() - predictions_df['Risk']) / \
                               (predictions_df['Risk'].max() - predictions_df['Risk'].min())

# Weighted Scoring
if risk_tolerance == 'high':
    predictions_df['Final_Score'] = 0.8 * predictions_df['Return_Score'] + 0.2 * predictions_df['Risk_Score']
elif risk_tolerance == 'intermediate':
    predictions_df['Final_Score'] = 0.5 * predictions_df['Return_Score'] + 0.5 * predictions_df['Risk_Score']
else:  # low
    predictions_df['Final_Score'] = 0.2 * predictions_df['Return_Score'] + 0.8 * predictions_df['Risk_Score']

# ---------------------------
# Step 7: Select Top N Stocks (Dynamic)
# ---------------------------
top_n = 10  # or determine dynamically based on diversification
top_stocks = predictions_df.sort_values(by='Final_Score', ascending=False).head(top_n)

# Normalize Weights
top_stocks['Weight'] = top_stocks['Final_Score'] / top_stocks['Final_Score'].sum()

# ---------------------------
# Step 8: Allocate Capital
# ---------------------------
top_stocks['Investment'] = top_stocks['Weight'] * investment_amount

# Optional: Convert to whole shares (if current prices are known)
# For now, just assume equal units - or plug in real prices here.

# ---------------------------
# Step 9: Display Portfolio
# ---------------------------
portfolio = top_stocks[['Predicted_Return', 'Risk', 'Sharpe', 'Weight', 'Investment']]
portfolio.sort_values(by='Weight', ascending=False, inplace=True)

print("\n📈 Suggested Optimized Portfolio Allocation:")
print(portfolio.round(4))

# ---------------------------
# Optional: Save to Excel
# ---------------------------
portfolio.to_excel("optimized_portfolio.xlsx")
print("\n✅ Portfolio saved to 'optimized_portfolio.xlsx'")

import matplotlib.pyplot as plt

def plot_allocation_pie(portfolio_df):
    plt.figure(figsize=(8, 8))
    plt.pie(portfolio_df['Investment'], labels=portfolio_df.index, autopct='%1.1f%%', startangle=140)
    plt.title("📊 Portfolio Allocation by Investment")
    plt.axis('equal')
    plt.tight_layout()
    plt.show()

def plot_predicted_returns(portfolio_df):
    plt.figure(figsize=(10, 5))
    portfolio_df['Predicted_Return'].sort_values().plot(kind='bar', color='skyblue')
    plt.title("📈 Predicted Annual Returns per Stock")
    plt.ylabel("Predicted Return")
    plt.grid(True, axis='y')
    plt.tight_layout()
    plt.show()

def plot_risk_vs_return(portfolio_df):
    plt.figure(figsize=(10, 6))
    plt.scatter(portfolio_df['Risk'], portfolio_df['Predicted_Return'], s=portfolio_df['Investment']/5, alpha=0.7)
    for i, txt in enumerate(portfolio_df.index):
        plt.annotate(txt, (portfolio_df['Risk'].iloc[i], portfolio_df['Predicted_Return'].iloc[i]), fontsize=8)
    plt.xlabel("Risk (Volatility)")
    plt.ylabel("Predicted Return")
    plt.title("⚖️ Risk vs Return")
    plt.grid(True)
    plt.tight_layout()
    plt.show()

plot_allocation_pie(portfolio)
plot_predicted_returns(portfolio)
plot_risk_vs_return(portfolio)

import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

def assign_sectors(df, sector_dict):
    """
    Assign sectors to stocks using a dictionary mapping.
    :param df: DataFrame with stock data (columns as stock names)
    :param sector_dict: Dictionary where key = stock name, value = sector
    :return: DataFrame with sector information
    """
    df_sectors = pd.DataFrame(columns=["Sector"], index=df.columns)
    for stock, sector in sector_dict.items():
        if stock in df.columns:
            df_sectors.loc[stock, 'Sector'] = sector
    return df_sectors

def cluster_stocks(df, n_clusters=5):
    """
    Perform PCA and KMeans clustering on stock returns to find similar behavior.
    :param df: DataFrame with stock returns (columns as stock names)
    :param n_clusters: Number of clusters
    :return: Cluster labels and PCA components
    """
    # Standardizing the returns (mean=0, std=1)
    standardized_df = (df - df.mean()) / df.std()

    # PCA for dimensionality reduction (helps in clustering)
    pca = PCA(n_components=2)  # Reduce to 2 components
    pca_components = pca.fit_transform(standardized_df.T)

    # KMeans clustering
    kmeans = KMeans(n_clusters=n_clusters)
    clusters = kmeans.fit_predict(pca_components)

    # Create a DataFrame with cluster labels
    cluster_df = pd.DataFrame(clusters, index=df.columns, columns=["Cluster"])

    # Plot clusters (optional)
    plt.figure(figsize=(8, 6))
    plt.scatter(pca_components[:, 0], pca_components[:, 1], c=clusters, cmap='viridis')
    for i, txt in enumerate(df.columns):
        plt.annotate(txt, (pca_components[i, 0], pca_components[i, 1]), fontsize=8)
    plt.title("⚖️ Stock Clusters (PCA + KMeans)")
    plt.xlabel("PCA Component 1")
    plt.ylabel("PCA Component 2")
    plt.grid(True)
    plt.show()

    return cluster_df

def ensure_sector_diversification(portfolio_df, sector_df, top_n=10):
    """
    Ensure portfolio diversification by limiting concentration in sectors.
    :param portfolio_df: DataFrame with portfolio information (stocks, weights, etc.)
    :param sector_df: DataFrame with sector assignments
    :param top_n: Top N stocks to consider in the portfolio
    :return: Diversified portfolio with sector constraints
    """
    # Filter top N stocks based on performance or any other criteria
    top_stocks = portfolio_df.head(top_n)

    # Track the sectors represented in the top N stocks
    selected_sectors = sector_df.loc[top_stocks.index, 'Sector'].value_counts()

    # If more than 3 sectors are represented, we are good.
    if len(selected_sectors) > 3:
        return top_stocks

    # Otherwise, try to add more diverse stocks from other sectors
    for sector in selected_sectors.index:
        # Add stocks from different sectors
        remaining_stocks = portfolio_df.loc[portfolio_df.index.difference(top_stocks.index)]
        alternative_stocks = remaining_stocks[sector_df.loc[remaining_stocks.index, 'Sector'] != sector]

        # Pick top stocks from different sectors until we have more diversification
        for stock in alternative_stocks.index:
            if len(selected_sectors) > 3:
                break
            selected_sectors[sector_df.loc[stock, 'Sector']] += 1
            top_stocks = top_stocks.append(portfolio_df.loc[stock])

    return top_stocks

sector_dict = {
    'SBI Life Insurance': 'Financials',
    'HDFC Life Insurance': 'Financials',
    'NTPC': 'Energy',
    'Britannia Industries': 'Consumer Goods',
    'UltraTech Cement': 'Materials',
    'Grasim Industries': 'Materials',
    'Cipla': 'Healthcare',
    'Axis Bank': 'Financials',
    'ITC': 'Consumer Goods',
    'HCL Technologies': 'Technology'
}
sector_df = assign_sectors(df, sector_dict)

cluster_df = cluster_stocks(daily_returns)
print(cluster_df)

diversified_portfolio = ensure_sector_diversification(portfolio, sector_df)
print(diversified_portfolio)